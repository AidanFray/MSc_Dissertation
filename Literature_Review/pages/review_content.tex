\section{Research questions}

Overall the research will aim to investigate the strength of pEp's Trustword fingerprint mappings, and the ease in which partial collisions can be obtained for keys and how this will ultimately affect the end user(s).

Key areas that will be looked into:
\begin{itemize}
    \item Is the recommended minimum number of Trustwords enough to provide a basic level of security.
    \item What attributes make a strong general wordlist for fingerprint mapping and does the Trustword implementation exhibit these features.
    \item How easy is it to generate similar keys that attack a targeted key pair?
    \item How can similarity be quantified in terms of words? Does this include pronunciation or visual aspects?
    \item As usability is the main justification for the use of Trustwords are there alternatives that provide the same usability but with more security?
\end{itemize}

\section{Review}

\subsection{Fingerprint representation and comparison}

Current research in ways to represent and validate fingerprints has almost exclusively focused on the usability of such schemes. The following section will individually discuss available research findings alongside a overall comparison of the research recommendations.

The first work in this area was performed by Hsu-Chun Hsiao, \textit{et. al.} in their paper: \textit{A Study of User-Friendly Hash Comparison Schemes}\cite{hsiao2009study} in around 2009.

The aim of the study was to provide the first insight into the best encoding scheme used to represent a hash fingerprint. The schemes used were Base32, English words, Random Art\footnote{A scheme proposed by A. Perrig \textit{et al.}\cite{perrig1999hash}}, Flag\footnote{Encoding scheme proposed by C Ellison \textit{et al.}\cite{ellison2003public}}, T-Flag\footnote{Yue-Hsun Lin \textit{et al.}\cite{lin2010spate} improvement on Flag}, Flag Ext\footnote{The author's own improvment on Flag} and finally Chinese, Korean and Japanese symbol encoding. 436 participants were assessed in the study.

Alongside the main aim of the paper, the authors wanted to provide empirical links between participant attributes such as age or gender to performance with the encoding scheme. This is something rarely seen in the related research. Hsu-Chun Hsiao \textit{et al.} also provided two categories of similarities; ``hard'' and ``easy''. These were designed to be worst and best case respectively. As a final aim and the reason for the inclusion of Chinese, Korean and Japanese characters was to research if being a native speaker assists the user in distinguishing subtle differences between encodings in the respective language.

The entropy of encodings ranged from 22-bits to 28-bits. This is extremely low in comparison to similar research. However, this can be attributed to the age of the paper due to its 10 year age and the time of writing. 

The authors decision to exclude hexadecimal and numerical encodings (some of the most widespread encoding schemes) was due to their similarity to Base32 and their well known deficiencies. This is not consistent with available research. For example, in \textit{``Empirical Study of Textual Key-Fingerprint Representations''} it was shown numerical representations performed better than that of Base32.

Overall, findings from the paper showed that age and gender does not affect the accuracy of the scheme, however younger participants were significantly faster. \\
The paper recommends Base32, Random Art, T-Flag or their own improvement; Flag Ext. These encoding recommendations were also supplemented with a review of requirements required by these schemes. The recommendation of graphical encoding schemes is inconsistent with alternative literature, where most other papers have found graphical encodings easy to use but insecure.
In terms of language comprehension; being able to speak the language assists in the ability to discern the differences between hard pairs. Knowledge of the language subsequently did not help with easy pairs.

In conclusion, the paper provided a very strong foundation for further research due to the wide variety of topics touched upon. However, its age means that results cannot be applicable to modern day scenarios, and oversights in the development of the study such as the exclusion of hexadecimal encoding and the lack of information gained on the perceived usability of the scheme from users results in an ultimately incomplete study.

Further research bu Kainda \textit{et al.}\cite{kainda2009usability} in 2009 investigated fingerprint representations and comparison methods in the context of using humans as the Out-Of-Band (OOB) channel for secure device pairing. This study was comprehensive and assessed a wide variety of concepts. This is one of the few papers in the literature that assessed the way to compare representations alongside the representations themselves.

For comparison methods that paper looked into Compare-and-Confirm, Compare-and-Select, Compare-and-Enter and Barcode scanning. This set includes the most common ways of comparison acording to available research. Alongside this, the paper reviews Numerical, Alphanumerical, Word, Sentences, Images, Melodies and Sound (Numerical/Alphanumerical). Again, this in comparison to similar literature is highly comprehensive.

In terms of empirical data gathered by the paper, they reviewed time completed to review the representation and the number of security and non-security related errors. Further more, the authors also collected user opinion on ease-of-use, satisfaction and confidence of the reviewed schemes. The overall schemes were then quantified using a single metric known as the Single Usability Metric (SUM)\cite{sauro2005method}. This provides a quick way to rank and compare the schemes, thus improving the usability of the results. 
However, the one apparent downside to the experimental side of the study is 40 participants enrolled. This in comparison to other studies is one of the smallest size of enrolment and thus, puts a possible limit on the accuracy and applicability of the obtained results. 

Overall, if usability is the only consideration the paper ranked the comparison methods like so: Compare-and-Confirm, Compare-and-Enter, Compare-and-Select and Barcode. If, however, the consideration of security alongside usability is required the best is Compare-and-Enter, Barcode, Compare-and-Confirm and Compare-and-Select. Research has been limited in this area of modes of comparison, however, the results from this paper are consistent with the alternative literature.
\\
In terms of encoding schemes the paper ranked Numerical, Alphanumerical and Words as the top three encoding schemes (These were all with Compare-and-Confirm). This took into consideration the usability and security of the scheme. This is relatively consistent with other literature where numerical and written encoding schemes seem to be the most effective overall.

In conclusion, this paper provided a highly comprehensive review of all the aspects of human fingerprint verification, where it reviewed all the elements involved in the human fingerprint verification. The only limitation of the paper is the size of the participants enrolled.

A paper by Ersin Uzun \textit{et al.} exclusively reviewed comparison methods. This is performed in the context of ``Secure device pairing'' and thus some comparison schemes are tested that are not relevant in a fingerprint comparison context, for example:  ``Choose-and-Enter'' (A participant chooses a passphrase from an available list and enters it into to the other device). Thus, only relevant comparison scheme and their results have been extracted and compared. 

The relevant comparison methods tested were, Compare-and-Confirm, Compare-and-Select and Compare-and-Enter. These are almost exactly the same encoding schemes assesed in the relevant research literature. The paper also had two rounds of experiments including 40 participants each where changes were made to UX and format between these studies.

Due to the ``Secure device pairing'' context the paper was written under, consideration needs to be made into the strings encoded. Due to secure device pairing commonly utilising Short Authentication Strings (SAS) the paper only reviewed encodings of 4 digit long strings. This, therefore, limits the applicability of the results to fingerprint encoding. This will be considered later when comparing the results to alternative literature.

Between the two rounds the authors dropped Confirm-and-Enter due to it low usability and over similarity to a similar scheme "Copy" used for passphrase verification. The low rating for Confirm-and-Enter is in contrast with research performed by Kainda \textit{et al.}\cite{kainda2009usability} They ranked Confirm-and-Enter as the 2nd most usable system.

With changes to the UX of Confirm-and-Confirm backed up by external research \cite{palmer1990attentional}\cite{hammer2009category} the second round of research was performed with a new set of participants. The alterations took Compare-and-Confirm from 20\% to 0\% fatal error rate (FER). The same trend for Confirm-and-Select with it reducing its FER from 12.5\% to 5\%. With the changes the participants perceived the systems as easy to use. The authors therefore recommended Compare-and-Confirm as the overall best choice for comparison methods. Again, comparing this word to the most similar work done by Kainda \textit{et al.}\cite{kainda2009usability} this is consistent with their findings where they ranked Compare-and-Confirm as the most secure comparison method.

Overall, the paper provides a sizeable insight into suitable methods of comparison, this is due to the cross over between fingerprint comparison and secure device pairing. This paper is limited in terms of the short strings compared, the different overall research aim and the size of the number of participants used in the studies. In terms of security of the schemes the results were constant with that of alternative research but clashed when usability was considered. This, however, may be due to the differing use-cases of the comparison methods and the sizes of strings being compared.

Work by Dechand Sergej, \textit{et al.}\cite{dechand2016empirical} empirically investigated the usability of 4 distinct textual representations evaluated with a experiments involving a total of 1047 participant. The textual representations were: Alphanumeric, Numeric, Words and Sentences. They assessed the number of attacks missed with each scheme alongside results from a questionnaire on the participants preferred scheme and perceived usability.

The paper touches upon issues with decentralised methods of identification such a PGP's Web of Trust and the problems these solutions have with user adoption. These points are made in an attempt to validate the requirement for manual comparison of key based fingerprints. This is a common theme that appears in the majority of the reviewed papers.

Other references made within the paper touch upon the vulnerabilities and usability issues present with the way humans interact with the security systems. Example of these are studies showing humans find it difficult to comprehend long and "meaningless" strings and the lack of actual comparison performed by users in live scenarios. These are, however, acknowledged as limitations in the later stages of the paper.

The paper has defined the upper and lower bound costs of the attacker's resources and strength as \$610K to \$16B, with an ability to control 80-bits of the fingerprint. This in comparison to other papers is high and is almost encroaching into the realm of a highly sophisticated attacker. Therefore, the lack of consideration for the lower-end of the attack resource spectrum can be considered a limitation of this study.

Overall, findings from the paper state that conventional encodings such as Hexadecimal and Base32 perform worse than all other alternatives in a realistic threat model with over 10\% of users failing to detect an attack on these encoding schemes. The recommendations of the authors is to to replace these encoding schemes with Words or Sentences due to their very high success rate and high usability scores. The performance of the Alphanumerical encoding schemes is relatively consistent with the literature, however, it is hard to say conclusively due to the small number and lack of visual encoding schemes reviewed making it hard to place alphanumerical encodings in an overall rating.

J Tan \textit{et al.} work is very similar to that of the research already discussed. 8 distinct fingerprint representations were tested with over 661 participants. Each representation was tested using Compare-and-Confirm and Compare-and-Select. The small difference with this paper is the inclusion of two novel graphical encodings Vash\footnote{https://github.com/thevash/vash} and Unicorns\footnote{https://unicornify.pictures/}. The compared schemes were: Hexadecimal, Alternating vowel/consonants, Words, Numbers, Sentences, OpenSSH visual host key, Vash and Unicorns.

The target security level chosen was an entropy of 160-bits. This is very high level of security and allows for the papers results to be effectively ``future-proofed''. Alongside this, the paper defined attack strengths of an average $2^{60}$ with other specific use-cases for lower and higher attacker strength. Users were recruited via MTurk and assigned an experiment attempting to emulate a real-life condition (Comparison of a fingerprint on a business card). The real-world accuracy was one unique element that this paper concentrated on, this was portrayed through the author's attention to detail when designing the experiment.

Overall, results from the experiments emulated previously discussed literature. Textual representations faired effectively well with Words and Sentences again being some of the best options overall. Performance of graphical representation was mixed with OpenSSH having performance matching that of a strong textual mapping while Unicorns having the worst performance overall. This performance with graphical representations is consistent with the available literature apart from the positive performance of OpenSSH. The results of different modes of comparison was highly consistent with other studies where again the recommendation was to not use Compare-and-Select as its performance across the board was below even basic levels of security.

\textbf{TODO: } Summarise research section

\section{Fingerprint encoding schemes}
Another area of research is investigation into the actual physical encodings of the hash digest. This section will briefly discuss the current research available on the creation and security of actual encoding schemes. The actual details of operation of the schemes are outside the scope of this literature review, therefore, minimal attention will be allocated to these details.

Some of the oldest preliminary work into visual encoding schemes was performed by Adrian Perrig \textit{et al}\cite{perrig1999hash}. in the creation of their scheme ``Random Art" in 1999. The motivation for creating such a scheme was the perceived flaws in the ways humans verify information and compare written information. As mentioned in previous sections visual encoding schemes have been shown to have mixed success, with low security being one of their most alarming flaws. This research laid the foundation for further work in analysing the security of visual encoding schemes (as discussed in the previous section) to the creation of new schemes.

Further research into creation of unique visual hash schemes have been performed by C Ellison \textit{et al.} \cite{ellison2003public} (Flag), Yue-Hsun Lin \textit{et al.}\cite{lin2010spate} (T-Flag) and work by MM Olembo \textit{et al.}\cite{olembo2013developing}. Each publication has provided a new way to visually represent a key fingerprint. This list is by no means exhaustive but is used to depict amount of research into this topic.

One paper of note is the preliminary work performed by D Loss \textit{et al.}\cite{loss2009drunken} in their \textit{``An analysis of the OpenSSH fingerprint visualization algorithm''} where their aim was to spur on further research with their initial findings into the security of the OpenSSH scheme. The authors claim that the use of the algorithm in OpenSSH is only heuristically defined and there is a need for a formal proof of its security. 

The paper proposed a number of ways to generate similar fingerprints. The methods proposed were: Naive brute force, graph theory methods, and brute force of a full visual set. They were able to produce only very basic results and have proposed a large amount of potential further work. Since the papers publication in 2009, there seems to have been no publications building on the work of the authors. This highlights a current gap in the available literature.

Minimal research has also focused on textual fingerprint representations and their respective security. Work by A. Karole and N. Saxena\cite{karole2009improving} is the only relevant research looking into ways to improve the security of a textual representation. This research aim is to improve the secure device pairing process of comparing two numerical values. The devices used (Nokia 6030b - Mid range devices at the time of publication) and short SAS compared results in findings that only slightly applicable in a fingerprint comparison context. 

Aside from this research there has been no other publications exploring the security textual representations. This clearly shows the presence of a sizeable research gap in the available literature.

{\small \textbf{TODO: } \textit{Need to double check this, I think there might have been some work into sentences}}

In conclusion to this topic, the current research has primarily focused on the research and creation of visual representations. This leaves a previously mentioned research gap for anything focusing primarily on the security and usability of encoding schemes such as words, or sentences.