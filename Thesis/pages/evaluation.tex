\chapter{Evaluation}
This chapter will collate the findings of the paper, evaluate the paper's success against the research questions and discuss potential further work.

\section{Research Question \ref{goal:numberOfTrustwords}}
Research Question \ref{goal:numberOfTrustwords} states \textit{`` Is the recommended minimum number of four Trustwords enough to provide a basic level of security?''}. The paper has investigated this through the creation of an attack and quantification of its success on actual participants. Findings have shown that an attack computed in half a day can have a success rate of about 9.35\%. A user, therefore, could initiate this attack on-mass with hardware present inside the average gaming computer. On the other hand, the best level of attack success was show to be 32.05\%. 

Further more, comparison of these results to similar literature show a huge increase in success rates for the attack present in this paper. All alternative literature used a small dictionary of around 1024 words. This, therefore, is highly suggestive that the issue lies with the design of Trustwords as present in the Trustword dictionary are multiple homophones and obscure and unpronounceable words. Therefore, we believe that 4 Trustwords as a minimum has not provided a basic level of security towards users.

\todo{Make this the last question to answer}

\section{Research Question \ref{goal:phoneticSimilarity}}

Research Question \ref{goal:phoneticSimilarity} asks: \textit{``What are the different ways phonetic similarity can be quantified?''}. This paper has discussed a number of metrics used to quantify phonetic similarly (See Section \ref{sec:metrics}). Most metrics were chosen due to their high utilization and occurrence in literature. The only exception to this is the presence of Phonetic Vectors that were chosen due to their unique qualities. This project has succeeded in presenting a comparison of ways to compare similarity metrics. A more in-depth comparison of all possible metrics is a substantial task and would require a project solely dedicated to this task.

\section{Research Question \ref{goal:bestMetrics}}
Research Question \ref{goal:bestMetrics} asks: \textit{``Out of a chosen set of metrics, which are the most effective?''}. 
The paper has presented the performance of a suite of algorithms that are mostly present in utilization and alternative literature. Performance of these metrics were quantified in a direct study that reduced the number down for 5 to 3. These newly selected metrics were then assessed in an attack context with their performance being indirectly quantified. From the historical set of metrics Levenshtein was the best performer with participants rating its matches as substantial better. Levenshtein was also the best performer in the attack context with it having a better average attack success rate that the alternative metrics. This, therefore, this work seems to corroborate work showing that words that are spelt in similar ways tend to share phonetic similarity \cite{hettiarachchi2012sparcl}. This area, however, will require further work to provide more conclusive results on the most effective ways to quantify phonetic similarity.

\section{Research Question \ref{goal:complexity}}
Research Question \ref{goal:complexity}: \textit{``What is the time and computation complexity required to generate a ’similar’ keys for a targeted key pair?''} has been discussed by the project, the actual generation of keys was shown in Section \ref{sec:key_gen} where actual keys were generated. Further more the distribution of key permutations on a set of real-world keys were discussed in Section \ref{sec:averagePerms} and \ref{sec:vulnKeys}. To achieve this the tool GreenOnion was developed where inspiration was gathered from a currently available tool known as Scallion. Experimentation results were gathered and displayed in Section \ref{sec:SvG} that showed the significant increase in the number of near-collision key GreenOnion can test for.

\section{Research Question \ref{goal:hardwareRequired}}
Research Question \ref{goal:hardwareRequired} states: \textit{``What kind of hardware is required to compute a matching key?''}. Through the computation of actual keys presented in Section \ref{sec:key_gen} and the theoretical calculation into key computation in some cases it has been shown that a single mid-range GPU\footnote{AMD RX-480} can be used to compute actual keys.

\section{Research Question \ref{goal:attackPercentage}}
Research Question \ref{goal:attackPercentage} \textit{``What percentage of attacks successfully deceive a user?''} was shown by the results presented in Section \ref{sec:exp2}. The weakest attack strength and ones that can be computed by a single mid-range GPU for a single week achieved success rate ranging from 9.35\% - 11.01\%. The middle attack involving the use of 10 mid-range GPUs for a week had success rates of 15.20\% - 19.20\%. Finally, the highest attack strength that theoretically involved the use of 100 mid-range GPUs computing for a week has success rates: 24.43\% - 32.05\%. Therefore, showing the number attacks would deceive a set assessed users.

\section{Further work}

\subsection*{Trustword improvements}
The first area of proposed work could be recommendations into how to improve Trustwords backed by empirical evidence. We feel the most promising avenue would be the utilization of Phonetic Vectors unique qualities to identify words of low quality by measuring very low vector distances. For example, present in the dictionary are the words \verb|THERE| and \verb|THEIR|, these could be massively improved upon and could result in a better quality word list. Moreover, utilizing the quantification of dissimilarity could be used to create a dictionary of maximized phonetic distance that could then be assessed in a similar way to detect the feasibility of the attack with the alterations and its success rate against users.

\subsection*{Similar metrics performance}
Another area of further work is the comprehensive assessment of algorithms used to assess phonetic similarity. The algorithms assessed in this work are a very small proportion of potential options. Thus, further work could assess the performance of metrics against each other to determine the one that works best with human models of phonetics. This could be achieved by repeating the improved experiment discussed in Section \ref{exp:metric}. This could be repeated with a very large number of metrics. Other elements for consideration could be age, location and dialect as variables that affect the metrics performance. 

\subsection*{GreenOnion optimizations}
Very little work and time was invested into improving the performance of GreenOnion as low-level optimizations are a very time consuming process. A project, therefore, could aim to improve on the performance already recorded in this paper. This could, therefore, improve on the performance of the attack and allow for more successful attacks to be computed in less time. 