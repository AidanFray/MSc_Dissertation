\chapter{Design}
\label{cha:Design}

This chapter will discuss and overview of the proposed attack and the elements that are required.

\section{Overall attack design}

The attack on Trustwords involves generating "near-collision" keys. These are keys that are deemed a match by the phonetic similar metric (More on this aspect in the following sections). A similarity metric is an algorithm designed to determine if two words are phonetically a match. For example, the words "THEIR" and "THERE" will be phonetically be a match whereas the words "DARK" and "PRINCIPLE" are not phonetically matching.

As each combined key in Trustwords is an exclusive-or of both sides public key (Figure \ref{fig:xor_trustwords} shows this process) the attack is target to a single pair of users and will require recomputation for every attack instance, this will be considered when discussing the attack feasibility. Each pair is also split into a "Uncontrolled" and "Controlled" key. Uncontrolled is the reciever of the communication, and, thus, we cannot control their key. The Controlled key is the one we are attempting to impersonate, and it is assumed that we have the ability to replace the Controlled key with our malicious option. These descriptions will be the terminology used throughout the paper. However, it should also be considered that the uncontrolled and controlled can be swapped around with the ability to compute both directions. Thus, resulting in the possibility to intercept both directions of communication. This, however, will require performing the attack separately for both directions.

\begin{figure}[h!]
    \centering
    $KeyFingerprint_{1} \oplus KeyFingerprint_{2} = TrustwordsFingerprint$
    \caption{Creation of the combined Trustword fingerprint}
    \label{fig:xor_trustwords}
\end{figure}

When attacking the respective similarity metric will be used to compute a list of possibilities for each position in the combined fingerprint.

Figure \ref{fig:nearMatch} shows the process of generating a sub section of the combinations. A list of each words matches are generated and then the total number of permutations are generated overall.

\begin{figure}[h!]
    \centering
    \begin{BVerbatim}[commandchars=\\\{\}]
        \centering
\textbf{ CHOKE BLUSHING FRIGHTENING HAND}
    \end{BVerbatim}
    \\
    \verb|COKE                           |
    \\
    \verb|SMOKE                          |
    \\
    \hspace{1cm}



    \verb|CHOKE                          |
    \\
    \begin{BVerbatim}[commandchars=\\\{\}]
\textbf{COKE BLUSHING FRIGHTENING HAND}
    \end{BVerbatim}
    \\
    \verb|SMOKE                          |
    \\
    \hspace{1cm}


    \verb|CHOKE                          |
    \\
    \verb|COKE                           |
    \\
    \begin{BVerbatim}[commandchars=\\\{\}]
        \centering
\textbf{ SMOKE BLUSHING FRIGHTENING HAND}
    \end{BVerbatim}
    \caption{Visualization of the generation of near matches}
    \label{fig:nearMatch}
\end{figure}

To generate an actual list of fingerprints to search for, the near collision words are converted back into hexadecimal and XORed with the uncontrolled key. The provides the impersonated key that will produce the desired combined near-collision. Completing this for all of the near-collision permutations will produce a list of fingerprints that can be inserted into a tool designed to hash keys and search for targets. This aspect of using a large list to search for keys massively reduces the complexity of the search.

In summary the, attack steps are:

\begin{enumerate}
    \item Compute all possible matches using a similarity metric on all words in a dictionary (Only needs performing once).

    \item Select a target and allocate "Uncontrolled" and "Controlled" key identification.
    
    \item Calculate all permutations of near-collisions for the key pair and produce a list of similar key fingerprints.
    
    \item Use list of similar keys in mass computation of keys to find near-collision keys.

\end{enumerate}

\subsection{Similarity metrics}

\subsubsection{Soundex}
One of the first requirements for the attack is quantifying "phonetic similarity". There are many algorithms currently available to provide this function, is known as Soundex. It is one of the most famous example of a phonetic algorithm due to its implementation into major database clients like MySQL\cite{mysql_soundex}, Oracle\cite{moved_2005} and PostgreSQL\cite{postgresql}. Originally designed for indexing names by sound alongside spelling mistakes due to small changes in letters. However, due to its design being based on the phonetic features it is highly suitable for this use-case. 

Soundex produces a four digit code for each word assessed.
The first letter of the word is retained alongside the removal of all of a, e, i, o, u, y, h and w. The remaining letters are then mapped to numbers.

\begin{figure}[h!]
    \centering
    \begin{BVerbatim}
b, f, p, v               1
c, g, j, k, q, s, x, z   2
d, t                     3
l                        4
m, n                     5
r                        6
    \end{BVerbatim}

    \caption{Soundex mappings of letters to numbers}
\end{figure}

Further steps are performed on the code, as the technical details do not add anything to the discussion, the steps of the algorithm can be found in Appendix TODO.

\subsubsection{Soundex Issues}

Due to the fixed length and limited digit set the initial concerns from this design is the limited number of combinations. There are a total of 5616 codes due to 26 initial letters and three digits of 6 values ($26 * 6^3$).
The limited combinations will result in matches of a limited quality. This will require consideration later in the project.

Further issues posed in \cite{patman2001soundex} are discussed below and show the further deficiencies of Soundex in a dictionary word matching context. 

\begin{enumerate}
    \item \textbf{Dependency on the first letter:} Soundex cannot match words together if their first letters are different, meaning for example the words "KORBIN" and "CORBIN" will never be matched.

    \item \textbf{Silent consonants.} Soundex does not have logic embedded to deal with silent consonants within words.

    \item \textbf{Poor precision.} Due to the previously discussed point of a small code resulting in lack of precision. \cite{patman2001soundex} re-iterates this point but in the context of name matching where Soundex's poor performance was demonstrated. Soundex only gained and overall accuracy 36.37\% when matching names within a database.
\end{enumerate}


However, even with Soundex's fallbacks its algorithmic simplicity and popularity allows it to still remain relevant in this application.

\subsubsection{NYSIIS}
The New York State Identification and Intelligence System (NYSIIS) phonetic code was created for use matching the phonetics of American names. It was created due to the presence of hispanic names in the American based databases (this was an aspect Soundex was known to have low accuracy with). However, due to it having embedded rules to handle word phonetics it would, again be applicable in this application.

It also allows for variable length codes and, thus, allows the applicability of the application to increase due to it not confronting the limited code issue of Soundex. It was in use right up the end of 1998 within various US Government departments. Due to this prolific stature and proven track record it was deemed suitable as one of the selected similarity metrics.

\subsubsection{Metaphone}
Metaphone was invented by Lawrence Philips in 1990\cite{philips1990hanging} in response to the deficienies in Soundex. It improves on Soundex by including information around inconsistency and variation in English spelling in an attempt to create a more accurate phonetic representation. Metaphone is arguably on the same level of ubiquity as that of Soundex with it finding itself implemented in languages such as big examples like PHP\cite{php}. Further work would involve the implementation of newer versions of Metaphone. Double Metaphone (2000) and Metaphone 3 (2009) claim to improve over the original version due to further research performed by Philips. The original version was chosen due to its historical wide spread usage alongside the case of Metaphone 3 being proprietary code and, therefore, under a paid licence.

\subsubsection{Levenshtien Distance}
Levenshtein distance is a string metric designed to measure the 'distance' between two strings. It is simply the number of single-character edits (insertions, deletions or substitutions) required to reach the other string. Edit distance is not technically designed as a phonetic algorithm, but due to similar-sounding words often being spelt in similar ways\cite{hettiarachchi2012sparcl} Levenshtien distance was deemed another suitable metric.

An example distance between \verb|trace| and \verb|place| would be the substitutions of the first to letters, from \verb|tr| to \verb|pl| meaning the two strings have a Levenshtein distance of 2.

\subsubsection{Phonetic Vectors}
Phonetic Vectors is the unique addition to the chosen set. Created by Allison Parrish in 2017\cite{parrish2017poetic}, Phonetic vectors is as the name suggests the vectorization of a words phonetics. This allows a words phonetics to be represented using a continuous number in vector space.

Phonetic features are used in this work as a way to compare the similarity of the phonemes. Extensive prior work has gone into producing models of features that map to phonemes. \cite{chomsky1968sound}\cite{ladefoged1969measurement}\cite{bradlow2010perceptual}. Features, therefore, a newer attempt at mapping the varying and inconsistent rules around pronunciation of the English language. The vectors are created using lists phonemes from the CMU Pronouncing Dictionary. Phonemes are the phonetic elements that construct a word. For example the word "RING" translated into the phonemes \verb|/R IH NG/|. Using all words available and mapping all phonemes to phonetic features a list of unique features is created per-word.

\begin{table}[!htb]
    \tiny
    \begin{minipage}{.33\linewidth}
        \centering
        \begin{tabular}{ll}
            Phone & Features \\
            \hline
            AA & bck, low, unr, vwl \\
            AE & fnt, low, unr, vwl \\
            AH & cnt, mid, unr, vwl \\
            AO & bck, lmd, rnd, vwl \\
            AW & bck, cnt, low, rnd, smh, unr, vwl \\
            AY & cnt, fnt, low, smh, unr, vwl \\
            B & blb, stp, vcd \\
            CH & alv, frc, stp, vls \\
            D & alv, stp, vcd \\
            DH & dnt, frc, vcd \\
            EH & fnt, lmd, unr, vwl \\
            ER & cnt, rzd, umd, vwl \\
            EY & fnt, lmd, smh, unr, vwl
        \end{tabular}
    \end{minipage}%
    \begin{minipage}{.33\linewidth}
        \centering
        \begin{tabular}{ll}
            Phone & Features \\
            \hline
            F &  frc, lbd, vls \\
            G &  stp, vcd, vel \\
            HH & apr, glt \\
            IH & fnt, smh, unr, vwl \\
            IY & fnt, hgh, unr, vwl \\
            JH & alv, frc, stp, vcd \\
            K &  stp, vel, vls \\
            L &  alv, lat \\
            M &  blb, nas \\
            N &  alv, nas \\
            NG & nas, vel \\
            OW & bck, rnd, smh, umd, vwl \\
            OY & bck, fnt, lmd, rnd, smh, unr, vwl
        \end{tabular}
    \end{minipage} 
    \begin{minipage}{.33\linewidth}
        \centering
        \begin{tabular}{ll}
            Phone & Features \\
            \hline
            P & blb, stp, vls \\
            R & alv, apr \\
            S & alv, frc, vls \\
            SH & frc, pla, vls \\
            T & alv, stp, vls \\
            TH & dnt, frc, vls \\
            UH & bck, rnd, smh, vwl \\
            UW & bck, hgh, rnd, vwl \\
            V & frc, lbd, vcd \\
            W & apr, lbv \\
            Y & apr, pal \\
            Z & alv, frc, vcd \\
            ZH & frc, pla, vcd \\
        \end{tabular}
    \end{minipage} 
    \caption{Phonemes to feature mapping table}
    \label{tab:features}
\end{table}

Table \ref{tab:features} contains the mappings used in \cite{parrish2017poetic} to create the phonetic feature lists.
Using this with all 133,852 entries in version 0.7b of the CMU Pronouncing Dictionary, 949 unique properties were produced overall. The author then performed principal components analysis\footnote{Details regarding this process is outside the scope of the project. Please, however, if interested please refer to this resource for more information: \url{http://setosa.io/ev/principal-component-analysis/}} on the unique properties to reduce them down to 50.

This metric allows for a unique set of actions to be performed on the phonetic output. Not only does this metric allow the user to measure \textit{dissimilarity} (opposed to the similar-or-not method of the alternatives) the continuous nature of the value allows mathematical operations to be performed on the output. An example shown in \cite{parrish2017poetic} was the addition of word vectors.

\begin{table}[!htb]
    \centering
    \begin{tabular}{cll}
        No & Operation & Result \\
        \hline
        1  & $Vec(\verb|sub|) + Vec(\verb|marine|)$ & \verb|submarine| \\
        2  & $Vec(\verb|miss|) + Vec(\verb|sieve|)$ & \verb|missive| \\
        3  & $Vec(\verb|fizz|) + Vec(\verb|theology|)$ & \verb|physiology| \\
    \end{tabular}
    \caption{Examples of vector addition}
    \label{tab:vectorAdd}
\end{table}

For example, the addition of vectors can be seen in Table \ref{tab:vectorAdd}. This works for any mathematical operation with multiplication allowing the 'tinting' words with a theme. 

\textbf{TODO: } Explain why being vectors is useful and its appliactions

\textbf{TODO: } Do a sample conversions table

\subsection{Alternative Similarity Metrics}

\subsubsection{Match Rating Approach}
Matching Rating Approach (MRA) is another algorithm designed to match names within a database, therefore, its operation can be grouped with that of NYSIIS and Soundex. MRA was discarded as an option. This is because of the lack of known utilization in any substantial real world use-cases alongside its similarity to more well established algorithms of Soundex and NYSIIS.

Further work could include the comparison of this algorithm  to similar alternatives in phonetically matching of words to quantify performance. This will be discussed further in the evaluative sections of the report.

\subsubsection{Caverphone}
Another notable alternative solution is that of Caverphone that was designed in New Zealand. Caverphone as is the case with the vast majority of phonetic algorithms was designed for use with name matching. Caverphone was not chosen to similar reasons to that of MRA alongside its optimization for accents in location of New Zealand it was conceived in. Therefore, the low level of utilization alongside the unique design features that suggest it may not be suited for this application. This has, however, not be assessed empirically and thus would be a candidate for further work.


% Other alternatives:
% - Match Rating Approach
%   - Couldn't find an algorithm??
%
% - Caverphone




\textbf{TODO: } Need to justify why


\section{Design of GreenOnion}
And the way it works. Need to explain it is based on Scallion but improved with the use of C++ alongside a bloom filter.