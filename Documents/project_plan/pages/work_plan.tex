\section{Title}

\begin{center}
    \textit{\large ``Security evaluation of pEp's TrustWord implementation"}
\end{center}

\section{Motivation}
\begin{itemize}
    \item Use-case for TrustWords: Users are often deterred by difficulty in key authentication and end-to-end encryption (e.g. PGP web-of-trust).

    \item Other word lists result in a higher number of words to compare. Trustwords mapping of a word to 2 bytes results in a lower number of words. Meaning the possibility of increased usability

    \item However, the mapping of words to 16-bits is yet to be proved as secure as this is the \textbf{highest number of bits per word}s seen in the literature. This results in the number of words required being higher than that of the users' vocabulary and even the number of total words in the respective language.
    
\end{itemize}

\section{Goals}

Overall the research will aim to investigate the strength of pEp's Trustword fingerprint mappings, and the ease in which partial collisions can be obtained for keys and how this will ultimately affect the end user(s). This will be accompanied by recommendations into how the TrustWord system can be altered to provide increased security alongside research into what makes an effective wordlist.

\newpage
\section{Possible research questions}
\begin{itemize}
    \item Is the recommended minimum number of Trustwords enough to provide a basic level of security?
    
    \item What attributes make a strong general wordlist for fingerprint mapping and does the Trustword implementation exhibit these features?
    
    \item What are some of the most effective ways of measuring linguistic distance or similarity?

    \item How easy is it to generate similar keys that attack a targeted key pair?
    
    \item How can the search for similar keys be assisted? Could weighting them like ``\textit{Fuzzy Fingerprints Attacking Vulnerabilities in the Human Brain}'' help to find partial matches?

    \item How can similarity be quantified in terms of words? Does this include pronunciation or visual aspects?
    
    \item As usability is the main justification for the use of Trustwords does the increase in usability justify the hypothesised reduction in security?
\end{itemize}

\newpage
\section{High Level View}

\subsection{Trustword attacks}

\subsubsection{Similarity metrics}
This section will discuss the feasibility of attacking 4 Trustwords. This will require "similar" words to be detected in the dictionary. Therefore, "similarity metrics" will be required.

Due to the defined use-case of Trustwords to be authenticated over a audio based channel, metrics that measure the pronoucability of a word will be used.

\textbf{[FURTHER WORK: Using metrics that consider the visual aspect of a word - this could be useful due to in-person authentication]}

\begin{itemize}
    \item Soundex
    \item NYSIIS
    \item Match Rating Approach
    \item Word Vectors
    \item Combined (With Levenshtein distance)
\end{itemize}

\textbf{[TODO] Experimentation: } Trimming down these metrics might be required with a quick pilot where I attempt to measure the user-perceived similarity accuracy of the schemes. What could be considered is the number of permutations and the "perceived" similarity.

\subsubsection{Similar list creation}
These metrics then can be used to substitute in place of other words to create a list of near-collision matches/permutations. These will help well generating near-collision keys.

\textbf{CONSIDERATION: } The method works by incrementing the exponent? How does this affect the structure of the key

\subsubsection{Tool design and creation}
Discussion will occur here around the creation of the tool. Will need to talk about the inspiration of the tool (Scallion) and the improvements made over it:
\begin{itemize}
    \item Benchmark of comparison of large number of keys.
    \item Why C++ was used?
\end{itemize}

\subsubsection{Study into the effectiveness of the matches}
The could be with the pilot where the results are extrapolated. There are two ways to run this study:

\begin{itemize}
    \item[1] Actual matches are computed and compared
    \item[2] Evaluation of complexity is computed prior, and for the experiment is simulated.
\end{itemize}

I think actually showing the matches can be actually computed and simulating them in the study gives the best balance. [Option 2]

Would I also want to do this with a random single target key? Or the worst case scenario. There are keys that have a higher number of potential matches, this is due to the words the key's fingerprint is mapped to.

\subsubsection{Conclusion of Trustword security}
This will have a conclusion stating the security of the minimum recommendation of 4 Trustwords.

\textbf{[FURTHER WORK: Evaluation with a higher number of words]}

\subsection{Improvement study}

This 
is recommendations into improvements with Trustwords. This will pretty much revolve around the word vectors and their ability to allow wordlist "strength" to be quantified. 

\subsection*{Word vectors}
The strength of the metric was shown in it's own paper with comparison with another famous study into an empirical way to vectorize words. This could even be linked back to the initial pilot study.

\textbf{[FURTHER WORK: More evaluation into the effectiveness of the word vector method]}

\subsection*{Choice of Trustwords}

\begin{itemize}
    \item Homographs (Spelt the same by pronounced differently)
    \item Homonyms   (Different spelling same pronunciation)
\end{itemize}

% https://en.wikipedia.org/wiki/Homograph#/media/File:Homograph_homophone_venn_diagram.png

Here I could make recommendations through improvements on the word lists:

\begin{itemize}
    \item Reduce the size of the wordlist (8bit (256 words)/10bits (1024 words))
    \item Different choice of words
    \item ?
\end{itemize}

These could then be evaluated in a similar way to show possible improvements over the base wordlist used by Trustwords

\textbf{[FURTHER WORK: Other languages found within Trustwords require this evaluation]}